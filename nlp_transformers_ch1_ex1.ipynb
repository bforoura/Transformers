{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyND75EsC5wpzZAfaQHj91r0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bforoura/Transformers/blob/main/nlp_transformers_ch1_ex1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "09cuVk_8YjBs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.special import softmax"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Step 1: Input : 3 inputs, d_model=4\")\n",
        "x =np.array([[1.0, 0.0, 1.0, 0.0],   # Input 1\n",
        "             [0.0, 2.0, 0.0, 2.0],   # Input 2\n",
        "             [1.0, 1.0, 1.0, 1.0]])  # Input 3\n",
        "\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAbRuVNmY0wM",
        "outputId": "bd2d34c5-15eb-4431-c4fd-3675801ebfe2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: Input : 3 inputs, d_model=4\n",
            "[[1. 0. 1. 0.]\n",
            " [0. 2. 0. 2.]\n",
            " [1. 1. 1. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Step 2: weights 3 dimensions x d_model=4\")\n",
        "\n",
        "w_query =np.array([[1, 0, 1],\n",
        "                   [1, 0, 0],\n",
        "                   [0, 0, 1],\n",
        "                   [0, 1, 1]])\n",
        "\n",
        "w_key =np.array([[0, 0, 1],\n",
        "                 [1, 1, 0],\n",
        "                 [0, 1, 0],\n",
        "                 [1, 1, 0]])\n",
        "\n",
        "w_value = np.array([[0, 2, 0],\n",
        "                    [0, 3, 0],\n",
        "                    [1, 0, 3],\n",
        "                    [1, 1, 0]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlBnVWiuZUzi",
        "outputId": "c234f574-c40b-43ac-e450-3b6bacb46afa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 2: weights 3 dimensions x d_model=4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"w_query\")\n",
        "print(w_query)\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print(\"w_key\")\n",
        "print(w_key)\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print(\"w_value\")\n",
        "print(w_value)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mpl-IoZxa9yZ",
        "outputId": "c0608b70-62a7-4473-c054-7b719383402b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w_query\n",
            "[[1 0 1]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 1 1]]\n",
            "\n",
            "w_key\n",
            "[[0 0 1]\n",
            " [1 1 0]\n",
            " [0 1 0]\n",
            " [1 1 0]]\n",
            "\n",
            "w_value\n",
            "[[0 2 0]\n",
            " [0 3 0]\n",
            " [1 0 3]\n",
            " [1 1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Step 3: Matrix multiplication to obtain Q,K,V\")\n",
        "print(\"Query: x * w_query\")\n",
        "\n",
        "Q=np.matmul(x,w_query)\n",
        "print(Q)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-oVfdXtbiNg",
        "outputId": "b00e6d34-2822-4f46-fcf6-843579ca91c8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 3: Matrix multiplication to obtain Q,K,V\n",
            "Query: x * w_query\n",
            "[[1. 0. 2.]\n",
            " [2. 2. 2.]\n",
            " [2. 1. 3.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Key: x * w_key\")\n",
        "K=np.matmul(x,w_key)\n",
        "print(K)\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Value: x * w_value\")\n",
        "V=np.matmul(x,w_value)\n",
        "print(V)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UQ4hCugd6qA",
        "outputId": "96640bd7-ca6c-46b9-9054-12b9d2302202"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Key: x * w_key\n",
            "[[0. 1. 1.]\n",
            " [4. 4. 0.]\n",
            " [2. 3. 1.]]\n",
            "\n",
            "Value: x * w_value\n",
            "[[1. 2. 3.]\n",
            " [2. 8. 0.]\n",
            " [2. 6. 3.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Step 4: Scaled Attention Scores\")\n",
        "k_d = 1   #square root of k_d=3 rounded down to 1 for this example\n",
        "attention_scores = (Q @ K.transpose())/k_d\n",
        "\n",
        "print(attention_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dPNbJbZeg_M",
        "outputId": "59c89f5b-1e52-4acb-cf89-af5922f77eef"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 4: Scaled Attention Scores\n",
            "[[ 2.  4.  4.]\n",
            " [ 4. 16. 12.]\n",
            " [ 4. 12. 10.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Step 5: Scaled softmax attention_scores for each vector\")\n",
        "\n",
        "attention_scores[0]=softmax(attention_scores[0])\n",
        "attention_scores[1]=softmax(attention_scores[1])\n",
        "attention_scores[2]=softmax(attention_scores[2])\n",
        "\n",
        "print(attention_scores[0])\n",
        "print(attention_scores[1])\n",
        "print(attention_scores[2])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhieDHifgNBR",
        "outputId": "3eee4b64-c270-48ea-b83e-230fc7d66e0f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 5: Scaled softmax attention_scores for each vector\n",
            "[0.06337894 0.46831053 0.46831053]\n",
            "[6.03366485e-06 9.82007865e-01 1.79861014e-02]\n",
            "[2.95387223e-04 8.80536902e-01 1.19167711e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Step 6: attention value obtained by score1/k_d * V\")\n",
        "print(V[0])\n",
        "print(V[1])\n",
        "print(V[2])\n",
        "\n",
        "print(\"Attention 1\")\n",
        "attention1=attention_scores[0].reshape(-1,1)\n",
        "attention1=attention_scores[0][0]*V[0]\n",
        "print(attention1)\n",
        "\n",
        "print(\"Attention 2\")\n",
        "attention2=attention_scores[0][1]*V[1]\n",
        "print(attention2)\n",
        "\n",
        "print(\"Attention 3\")\n",
        "attention3=attention_scores[0][2]*V[2]\n",
        "print(attention3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZi0cA1_hauO",
        "outputId": "2d73f1ad-9c81-4ff4-d569-401be6620235"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 6: attention value obtained by score1/k_d * V\n",
            "[1. 2. 3.]\n",
            "[2. 8. 0.]\n",
            "[2. 6. 3.]\n",
            "Attention 1\n",
            "[0.06337894 0.12675788 0.19013681]\n",
            "Attention 2\n",
            "[0.93662106 3.74648425 0.        ]\n",
            "Attention 3\n",
            "[0.93662106 2.80986319 1.40493159]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Step7: summed the results to create the first line of the output matrix\")\n",
        "attention_input1 = attention1+attention2+attention3\n",
        "\n",
        "print(attention_input1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1orDHUQjEWS",
        "outputId": "4205477a-2cfb-4e9f-e23d-b958d359faab"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step7: summed the results to create the first line of the output matrix\n",
            "[1.93662106 6.68310531 1.59506841]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Step 8: Step 1 to 7 for inputs 1 to 3\")\n",
        "#We assume we have 3 results with learned weights (they were not trained in this example)\n",
        "#We assume we are implementing the original Transformer paper. We will have 3 results of 64 dimensions each\n",
        "\n",
        "attention_head1=np.random.random((3, 64))\n",
        "print(attention_head1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhYQsCXrkLBn",
        "outputId": "e7678171-6b99-4e17-d5b3-8266781ce3d9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 8: Step 1 to 7 for inputs 1 to 3\n",
            "[[0.13148203 0.03829168 0.2861673  0.31683066 0.86577224 0.80289711\n",
            "  0.26612834 0.96102523 0.38889388 0.19143942 0.68095002 0.06567193\n",
            "  0.31257388 0.40147144 0.24104979 0.4254851  0.4240913  0.82164621\n",
            "  0.12624546 0.13767719 0.09382273 0.348346   0.74473046 0.14426032\n",
            "  0.88146838 0.07769864 0.73300855 0.39572125 0.03165128 0.10091833\n",
            "  0.10874704 0.2888105  0.27107165 0.76688586 0.24758366 0.20043679\n",
            "  0.73354091 0.60211126 0.01949827 0.80549637 0.17158278 0.59693327\n",
            "  0.90329506 0.13319332 0.53164499 0.29662379 0.92201489 0.19226347\n",
            "  0.48081424 0.61344444 0.86574986 0.86009255 0.79683483 0.26662833\n",
            "  0.40325268 0.11063081 0.58244665 0.11101545 0.44066732 0.20238456\n",
            "  0.52893348 0.62074621 0.38880004 0.09131379]\n",
            " [0.27282496 0.04187776 0.88978867 0.37223828 0.49526882 0.18930514\n",
            "  0.75242757 0.18093828 0.26784013 0.36987726 0.76751937 0.63509726\n",
            "  0.21152427 0.37293889 0.87135326 0.43389632 0.36783138 0.14234065\n",
            "  0.75890675 0.29176423 0.65761945 0.24975873 0.57617113 0.49021309\n",
            "  0.3131301  0.8842175  0.38814814 0.83524252 0.34571615 0.96323079\n",
            "  0.81781429 0.6349757  0.3682855  0.75313099 0.11043621 0.6958484\n",
            "  0.40801755 0.52016324 0.96783624 0.86848539 0.56629655 0.66628913\n",
            "  0.15190525 0.29571889 0.54355658 0.64634351 0.77501015 0.33275129\n",
            "  0.77405263 0.1967927  0.7481916  0.29194172 0.14146443 0.36139555\n",
            "  0.3283449  0.84383774 0.52277237 0.96726265 0.2408422  0.6365504\n",
            "  0.90028326 0.34409823 0.79980863 0.2058403 ]\n",
            " [0.62987217 0.76336821 0.13964343 0.61314055 0.91892201 0.14918578\n",
            "  0.441811   0.86892178 0.67579873 0.70883089 0.12401632 0.18992529\n",
            "  0.0860126  0.54667414 0.79153738 0.34840885 0.9474269  0.22149561\n",
            "  0.41399369 0.02206001 0.77277825 0.28493584 0.91075928 0.98798193\n",
            "  0.9096924  0.66003746 0.72803505 0.90680566 0.37927873 0.35759345\n",
            "  0.35571971 0.70567057 0.45979733 0.99293867 0.74447543 0.03379987\n",
            "  0.0812823  0.15744148 0.98552582 0.28144601 0.04697785 0.64508585\n",
            "  0.73731    0.93786043 0.90613744 0.53367537 0.28090747 0.63894089\n",
            "  0.24639617 0.78606865 0.9732996  0.45987931 0.93627842 0.52067323\n",
            "  0.6898605  0.72152038 0.26664264 0.49640563 0.35728735 0.95129107\n",
            "  0.04455197 0.17882403 0.49932523 0.79544263]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Step 9: We assume we have trained the 8 heads of the attentionsub-layer\")\n",
        "z0h1=np.random.random((3, 64))\n",
        "z1h2=np.random.random((3, 64))\n",
        "z2h3=np.random.random((3, 64))\n",
        "z3h4=np.random.random((3, 64))\n",
        "z4h5=np.random.random((3, 64))\n",
        "z5h6=np.random.random((3, 64))\n",
        "z6h7=np.random.random((3, 64))\n",
        "z7h8=np.random.random((3, 64))\n",
        "\n",
        "print(\"shape of one head\",z0h1.shape,\"dimension of 8 heads\",64*8)\n"
      ],
      "metadata": {
        "id": "3LcpYrb1mGUf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eaf8726-091b-49a7-e233-face2a3df4b5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 9: We assume we have trained the 8 heads of the attentionsub-layer\n",
            "shape of one head (3, 64) dimension of 8 heads 512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Step 10: Concantenation of heads 1 to 8 to obtain the original 8x64=512 ouput dimension of the model\")\n",
        "output_attention=np.hstack((z0h1,z1h2,z2h3,z3h4,z4h5,z5h6,z6h7,z7h8))\n",
        "\n",
        "print(output_attention)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3oqqm_v7JIG",
        "outputId": "5db068e9-8f12-47a2-a905-7d009a533929"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 10: Concantenation of heads 1 to 8 to obtain the original 8x64=512 ouput dimension of the model\n",
            "[[0.61742966 0.61558092 0.25181767 ... 0.23635132 0.37672259 0.61960927]\n",
            " [0.3847216  0.05432725 0.44269613 ... 0.32515866 0.45396557 0.43783078]\n",
            " [0.81253515 0.1135622  0.79508043 ... 0.0579154  0.65363546 0.08278254]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We first ensure that Hugging Face's transformers are installed:\n",
        "\n",
        "!pip -qq install transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGE-qthY7aGx",
        "outputId": "f651f9fe-c84c-4e07-a6ee-91cd2f974ca2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.9 MB 5.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 39.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 163 kB 69.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We then import the Hugging Face pipeline, which contains several transformer usages:\n",
        "\n",
        "from transformers import pipeline\n",
        "\n"
      ],
      "metadata": {
        "id": "ZQrEsRYNFurM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  to illustrate the Transformer model of this chapter, we activate the \n",
        "# translator model and enter a sentence to translate from English to French:\n",
        "\n",
        "translator = pipeline(\"translation_en_to_fr\")\n",
        "\n",
        "#One line of code!\n",
        "print(translator(\"It is easy to translate languages with transformers\", max_length=40))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcEsNyvtGBfi",
        "outputId": "4325691f-1257-485e-8ed7-fd35c2f30b0a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to t5-base and revision 686f1db (https://huggingface.co/t5-base).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'translation_text': \"Il est facile de traduire des langues à l'aide de transformateurs\"}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RzFPseUsGjb8"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}